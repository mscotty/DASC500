{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f70cd14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 20:57:02,358 - ERROR - Error loading satellite database: 'utf-8' codec can't decode byte 0xa0 in position 29318: invalid start byte\n",
      "2025-05-25 20:57:02,358 - INFO - Attempting to load satellite database with ISO-8859-1 encoding...\n",
      "2025-05-25 20:57:02,861 - INFO - Satellite Database successfully loaded with ISO-8859-1 encoding.\n",
      "2025-05-25 20:57:03,546 - INFO - Military Bases Database successfully loaded.\n",
      "2025-05-25 20:57:03,836 - INFO - Q2: All required satellite columns are present.\n",
      "2025-05-25 20:57:04,118 - INFO - Satellite Pandas pivot table saved to 'satellite_pivot_pandas.csv'\n",
      "2025-05-25 20:57:04,143 - INFO - Connected to database: analysis_database.sqlite\n",
      "2025-05-25 20:57:04,274 - INFO - DataFrame successfully loaded into table 'satellite_info'. Cleaned columns: ['name_of_satellite_alternate_names', 'country_of_operator_owner', 'purpose', 'detailed_purpose', 'class_of_orbit']\n",
      "2025-05-25 20:57:04,372 - INFO - DataFrame successfully loaded into table 'satellite_tech_specs'. Cleaned columns: ['name_of_satellite_alternate_names', 'launch_mass_kg', 'power_watts', 'date_of_launch', 'expected_lifetime_yrs']\n",
      "2025-05-25 20:57:04,381 - INFO - Satellite data loaded into SQL tables.\n",
      "2025-05-25 20:57:04,381 - INFO - Executing SQL query for satellite pivot...\n",
      "2025-05-25 20:57:04,545 - INFO - SQL pivot table saved to 'satellite_pivot_sql.csv'\n",
      "2025-05-25 20:57:04,553 - INFO - Disconnected from database: analysis_database.sqlite\n",
      "2025-05-25 20:57:04,578 - INFO - Q3: All required military base columns are present.\n",
      "2025-05-25 20:57:08,168 - INFO - Connected to database: analysis_database.sqlite\n",
      "2025-05-25 20:57:08,231 - INFO - DataFrame successfully loaded into table 'base_info'. Cleaned columns: ['site_name', 'state_terr', 'component', 'joint_base', 'oper_stat']\n",
      "2025-05-25 20:57:08,328 - INFO - DataFrame successfully loaded into table 'base_geometrics'. Cleaned columns: ['site_name', 'area', 'perimeter', 'shape_leng', 'shape_area']\n",
      "2025-05-25 20:57:08,328 - INFO - Military base data loaded into SQL tables.\n",
      "2025-05-25 20:57:08,336 - INFO - Registered 'stdev' aggregate function in SQLite.\n",
      "2025-05-25 20:57:08,336 - INFO - Executing SQL query for military groupby...\n",
      "2025-05-25 20:57:08,437 - INFO - Disconnected from database: analysis_database.sqlite\n",
      "2025-05-25 20:57:08,550 - INFO - State strategic profile (Pandas) saved to 'state_strategic_profile_pandas.csv'\n",
      "2025-05-25 20:57:08,632 - INFO - State strategic profile (SQL) saved to 'state_strategic_profile_sql.csv'\n",
      "2025-05-25 20:57:08,657 - INFO - Starting Question 4: Multi-Level Pivoting (Satellite Data)\n",
      "2025-05-25 20:57:08,976 - INFO - Satellite multi-level pivot (counts) saved to 'satellite_multilevel_pivot_counts.csv'\n",
      "2025-05-25 20:57:09,051 - INFO - Satellite percentage growth pivot saved to 'satellite_percentage_growth_pivot.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3 \n",
    "import re\n",
    "import logging \n",
    "\n",
    "from DASC500.utilities.get_top_level_module import get_top_level_module_path\n",
    "from DASC500.utilities.print.redirect_print import redirect_print\n",
    "\n",
    "# Set pathing for input csv files and output directory\n",
    "TOP_PATH = os.path.join(get_top_level_module_path(), \"../..\")\n",
    "DATA_PATH = os.path.join(TOP_PATH, \"data/DASC501/homework7\")\n",
    "ucs_satellite_db_path = os.path.join(DATA_PATH, \"UCS-Satellite-Database-1-1-2023.csv\")\n",
    "military_bases_db_path = os.path.join(DATA_PATH, \"military-bases.csv\")\n",
    "OUTPUT_PATH = os.path.join(TOP_PATH, \"outputs/DASC501/homework7\")\n",
    "\n",
    "redirect_print(\n",
    "    os.path.join(OUTPUT_PATH, \"mls_homework7_output.txt\"), also_to_stdout=True\n",
    ")\n",
    "\n",
    "# Configure basic logging for the script\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "# --- Question 1: Read CSV files ---\n",
    "print(\"--- Question 1: Reading CSV files ---\")\n",
    "\n",
    "# Load the satellite database\n",
    "try:\n",
    "    # UCS-Satellite-Database-1-1-2023.csv\n",
    "    satellite_df = pd.read_csv(ucs_satellite_db_path)\n",
    "    logging.info(\"Satellite Database successfully loaded.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading satellite database: {e}\")\n",
    "    try:\n",
    "        logging.info(\n",
    "            \"Attempting to load satellite database with ISO-8859-1 encoding...\"\n",
    "        )\n",
    "        satellite_df = pd.read_csv(ucs_satellite_db_path, encoding=\"ISO-8859-1\")\n",
    "        logging.info(\"Satellite Database successfully loaded with ISO-8859-1 encoding.\")\n",
    "    except Exception as e_iso:\n",
    "        logging.error(\n",
    "            f\"Error loading satellite database with ISO-8859-1 encoding: {e_iso}\"\n",
    "        )\n",
    "        # Later try not needed but demonstrates handling of a more complicated file\n",
    "        try:\n",
    "            logging.info(\n",
    "                \"Attempting to load satellite database by skipping bad lines...\"\n",
    "            )\n",
    "            satellite_df = pd.read_csv(\n",
    "                ucs_satellite_db_path, encoding=\"ISO-8859-1\", on_bad_lines=\"skip\"\n",
    "            )\n",
    "            logging.info(\n",
    "                \"Satellite Database successfully loaded with ISO-8859-1 encoding and skipping bad lines.\"\n",
    "            )\n",
    "        except Exception as e_skip:\n",
    "            logging.error(f\"Could not load satellite database: {e_skip}\")\n",
    "            satellite_df = pd.DataFrame()\n",
    "\n",
    "# Load the military bases database (this one is simpler and does not require encoding)\n",
    "try:\n",
    "    military_bases_df = pd.read_csv(military_bases_db_path, delimiter=\";\")\n",
    "    logging.info(\"Military Bases Database successfully loaded.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading military bases database: {e}\")\n",
    "    military_bases_df = pd.DataFrame()\n",
    "\n",
    "# Check the loaded DataFrames\n",
    "# Inspect the satellite_df\n",
    "if not satellite_df.empty:\n",
    "    print(\"\\n--- Satellite Database Info ---\")\n",
    "    print(\"Head:\")\n",
    "    print(satellite_df.head())\n",
    "    print(\"\\nInfo:\")\n",
    "    satellite_df.info()\n",
    "    print(\"\\nColumns before cleaning:\")\n",
    "    print(satellite_df.columns)\n",
    "    original_satellite_columns = satellite_df.columns\n",
    "    satellite_df.columns = [\n",
    "        re.sub(r\"\\W+\", \"_\", col).lower().strip(\"_\") for col in satellite_df.columns\n",
    "    ]\n",
    "    print(\"\\nCleaned Satellite DF Columns:\")\n",
    "    print(satellite_df.columns)\n",
    "\n",
    "# Inspect the military_bases_df\n",
    "if not military_bases_df.empty:\n",
    "    print(\"\\n--- Military Bases Database Info ---\")\n",
    "    print(\"Head:\")\n",
    "    print(military_bases_df.head())\n",
    "    print(\"\\nInfo:\")\n",
    "    military_bases_df.info()\n",
    "    print(\"\\nColumns before cleaning:\")\n",
    "    print(military_bases_df.columns)\n",
    "    original_military_columns = military_bases_df.columns\n",
    "    military_bases_df.columns = [\n",
    "        re.sub(r\"\\W+\", \"_\", col).lower().strip(\"_\") for col in military_bases_df.columns\n",
    "    ]\n",
    "    print(\"\\nCleaned Military Bases DF Columns:\")\n",
    "    print(military_bases_df.columns)\n",
    "\n",
    "\n",
    "# Database Manager (simplified this class for this example)\n",
    "class DatabaseManager:\n",
    "    def __init__(self, db_path):\n",
    "        self.db_path = db_path\n",
    "        self.conn = None\n",
    "        self.logger = logging.getLogger(__name__)  # Uses the logging imported above\n",
    "        # self.logger.setLevel(logging.INFO) # Ensure logger level is set if not using basicConfig root\n",
    "\n",
    "    def connect(self):\n",
    "        try:\n",
    "            self.conn = sqlite3.connect(self.db_path)\n",
    "            self.logger.info(f\"Connected to database: {self.db_path}\")\n",
    "        except sqlite3.Error as e:\n",
    "            self.logger.error(f\"Error connecting to database {self.db_path}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def disconnect(self):\n",
    "        if self.conn:\n",
    "            self.conn.close()\n",
    "            self.conn = None  # Set to None after closing\n",
    "            self.logger.info(f\"Disconnected from database: {self.db_path}\")\n",
    "\n",
    "    def execute_query(self, query, params=None):\n",
    "        if not self.conn:\n",
    "            self.connect()\n",
    "        try:\n",
    "            cursor = self.conn.cursor()\n",
    "            cursor.execute(query, params or ())\n",
    "            self.conn.commit()\n",
    "            return cursor\n",
    "        except sqlite3.Error as e:\n",
    "            self.logger.error(\n",
    "                f\"Error executing query: {query} with params {params}. Error: {e}\"\n",
    "            )\n",
    "            raise\n",
    "\n",
    "    def fetch_query(self, query, params=None):\n",
    "        if not self.conn:\n",
    "            self.connect()\n",
    "        try:\n",
    "            cursor = self.conn.cursor()\n",
    "            cursor.execute(query, params or ())\n",
    "            return cursor.fetchall()\n",
    "        except sqlite3.Error as e:\n",
    "            self.logger.error(\n",
    "                f\"Error fetching query: {query} with params {params}. Error: {e}\"\n",
    "            )\n",
    "            raise\n",
    "\n",
    "    def df_to_table(self, df, table_name, if_exists=\"replace\", index=False):\n",
    "        if not self.conn:\n",
    "            self.connect()\n",
    "        try:\n",
    "            # Clean column names for SQL compatibility if not already done\n",
    "            clean_cols = [\n",
    "                re.sub(r\"\\W+\", \"_\", col).lower().strip(\"_\") for col in df.columns\n",
    "            ]\n",
    "            df_copy = df.copy()\n",
    "            df_copy.columns = clean_cols\n",
    "            df_copy.to_sql(table_name, self.conn, if_exists=if_exists, index=index)\n",
    "            self.logger.info(\n",
    "                f\"DataFrame successfully loaded into table '{table_name}'. Cleaned columns: {clean_cols}\"\n",
    "            )\n",
    "        except Exception as e:  # Catch pandas or sqlite3 errors\n",
    "            self.logger.error(f\"Error loading DataFrame into table '{table_name}': {e}\")\n",
    "            raise\n",
    "\n",
    "# Instantiate DatabaseManager for later problems\n",
    "db_manager = DatabaseManager(\"analysis_database.sqlite\")\n",
    "\n",
    "# Question 2: Pivot Tables in Pandas vs. SQL (Satellite Data)\n",
    "print(\"\\n\\n--- Question 2: Pivot Tables (Satellite Data) ---\")\n",
    "if not satellite_df.empty:\n",
    "    # Column names after cleaning (refer to print(satellite_df.columns) output)\n",
    "    name_col_sat = \"name_of_satellite_alternate_names\"\n",
    "    country_col = \"country_of_operator_owner\"\n",
    "    purpose_col = \"purpose\"\n",
    "    detailed_purpose_col = \"detailed_purpose\"\n",
    "    orbit_class_col = \"class_of_orbit\"\n",
    "    mass_col = \"launch_mass_kg\"\n",
    "    power_col = \"power_watts\"\n",
    "    launch_date_col = \"date_of_launch\"\n",
    "    lifetime_col = \"expected_lifetime_yrs\"\n",
    "\n",
    "    required_q2_cols = [\n",
    "        name_col_sat,\n",
    "        country_col,\n",
    "        purpose_col,\n",
    "        detailed_purpose_col,\n",
    "        orbit_class_col,\n",
    "        mass_col,\n",
    "        power_col,\n",
    "        launch_date_col,\n",
    "        lifetime_col,\n",
    "    ]\n",
    "    actual_sat_cols = satellite_df.columns\n",
    "    missing_q2_cols = [col for col in required_q2_cols if col not in actual_sat_cols]\n",
    "\n",
    "    if missing_q2_cols:\n",
    "        logging.error(\n",
    "            f\"Q2: Missing critical satellite columns after cleaning: {missing_q2_cols}. Available: {actual_sat_cols}\"\n",
    "        )\n",
    "    else:\n",
    "        logging.info(\"Q2: All required satellite columns are present.\")\n",
    "        \n",
    "        # Table 1: Basic satellite information\n",
    "        satellite_info_df = satellite_df[\n",
    "            [\n",
    "                name_col_sat,\n",
    "                country_col,\n",
    "                purpose_col,\n",
    "                detailed_purpose_col,\n",
    "                orbit_class_col,\n",
    "            ]\n",
    "        ].copy()\n",
    "        \n",
    "        # Table 2: Technical specifications\n",
    "        satellite_tech_df = satellite_df[\n",
    "            [name_col_sat, mass_col, power_col, launch_date_col, lifetime_col]\n",
    "        ].copy()\n",
    "\n",
    "        # Clean numeric columns in technical specs table\n",
    "        for col_to_clean in [mass_col, power_col]:\n",
    "            if col_to_clean in satellite_tech_df.columns:\n",
    "                satellite_tech_df[col_to_clean] = (\n",
    "                    satellite_tech_df[col_to_clean]\n",
    "                    .astype(str)\n",
    "                    .str.replace(\",\", \"\", regex=False)\n",
    "                )\n",
    "                satellite_tech_df[col_to_clean] = pd.to_numeric(\n",
    "                    satellite_tech_df[col_to_clean], errors=\"coerce\"\n",
    "                )\n",
    "\n",
    "        # Merge the two tables\n",
    "        merged_satellite_df = pd.merge(\n",
    "            satellite_info_df, satellite_tech_df, on=name_col_sat, how=\"inner\"\n",
    "        )\n",
    "        \n",
    "        print(\"\\n-- Pandas Implementation (Satellite) --\")\n",
    "        print(\"Satellite Info Table (head):\")\n",
    "        print(satellite_info_df.head())\n",
    "        print(\"\\nSatellite Technical Specs Table (head):\")\n",
    "        print(satellite_tech_df.head())\n",
    "        print(\"\\nMerged Satellite Table (head):\")\n",
    "        print(merged_satellite_df.head())\n",
    "\n",
    "        try:\n",
    "            # Create comprehensive pivot table with multiple aggregations\n",
    "            satellite_pivot_pandas = pd.pivot_table(\n",
    "                merged_satellite_df,\n",
    "                index=[purpose_col, detailed_purpose_col],  # Two-level hierarchy\n",
    "                columns=country_col,\n",
    "                values=[name_col_sat, mass_col, power_col],  # Multiple values\n",
    "                aggfunc={\n",
    "                    name_col_sat: 'count',    # Count of satellites\n",
    "                    mass_col: 'mean',         # Average launch mass\n",
    "                    power_col: 'mean'         # Average power\n",
    "                },\n",
    "                fill_value=0\n",
    "            )\n",
    "            print(\"\\nPandas Pivot Table (Satellite - Multi-level with Multiple Aggregations):\")\n",
    "            print(satellite_pivot_pandas.head(10))\n",
    "            \n",
    "            # Save to CSV\n",
    "            satellite_pivot_pandas.to_csv(\n",
    "                os.path.join(OUTPUT_PATH, \"satellite_pivot_pandas.csv\")\n",
    "            )\n",
    "            logging.info(\n",
    "                \"Satellite Pandas pivot table saved to 'satellite_pivot_pandas.csv'\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error creating Pandas pivot table for satellites: {e}\")\n",
    "\n",
    "        print(\"\\n-- SQL Implementation (Satellite) --\")\n",
    "        try:\n",
    "            db_manager.connect()\n",
    "            \n",
    "            # Load data into SQL tables\n",
    "            db_manager.df_to_table(\n",
    "                satellite_info_df, \"satellite_info\", if_exists=\"replace\"\n",
    "            )\n",
    "            db_manager.df_to_table(\n",
    "                satellite_tech_df, \"satellite_tech_specs\", if_exists=\"replace\"\n",
    "            )\n",
    "            logging.info(\"Satellite data loaded into SQL tables.\")\n",
    "\n",
    "            # SQL query to replicate the pivot table logic\n",
    "            sql_query_satellite = f\"\"\"\n",
    "            SELECT\n",
    "                si.\"{purpose_col}\", \n",
    "                si.\"{detailed_purpose_col}\", \n",
    "                si.\"{country_col}\",\n",
    "                COUNT(si.\"{name_col_sat}\") AS satellite_count,\n",
    "                AVG(CAST(st.\"{mass_col}\" AS FLOAT)) AS avg_launch_mass,\n",
    "                AVG(CAST(st.\"{power_col}\" AS FLOAT)) AS avg_power\n",
    "            FROM satellite_info si\n",
    "            JOIN satellite_tech_specs st ON si.\"{name_col_sat}\" = st.\"{name_col_sat}\"\n",
    "            WHERE st.\"{mass_col}\" IS NOT NULL \n",
    "                AND st.\"{power_col}\" IS NOT NULL\n",
    "                AND si.\"{country_col}\" IS NOT NULL\n",
    "            GROUP BY si.\"{purpose_col}\", si.\"{detailed_purpose_col}\", si.\"{country_col}\"\n",
    "            ORDER BY si.\"{purpose_col}\", si.\"{detailed_purpose_col}\", si.\"{country_col}\";\n",
    "            \"\"\"\n",
    "            \n",
    "            logging.info(\"Executing SQL query for satellite pivot...\")\n",
    "            satellite_pivot_sql_results = db_manager.fetch_query(sql_query_satellite)\n",
    "\n",
    "            if satellite_pivot_sql_results:\n",
    "                # Convert SQL results to DataFrame\n",
    "                satellite_pivot_sql_df = pd.DataFrame(\n",
    "                    satellite_pivot_sql_results,\n",
    "                    columns=[\n",
    "                        purpose_col,\n",
    "                        detailed_purpose_col,\n",
    "                        country_col,\n",
    "                        \"satellite_count\",\n",
    "                        \"avg_launch_mass\",\n",
    "                        \"avg_power\",\n",
    "                    ],\n",
    "                )\n",
    "                \n",
    "                # Create pivot table from SQL results to match Pandas format\n",
    "                satellite_pivot_sql_pivoted = satellite_pivot_sql_df.pivot_table(\n",
    "                    index=[purpose_col, detailed_purpose_col],\n",
    "                    columns=country_col,\n",
    "                    values=[\"satellite_count\", \"avg_launch_mass\", \"avg_power\"],\n",
    "                    fill_value=0\n",
    "                )\n",
    "                \n",
    "                print(\"\\nSQL Pivot Table (Satellite - Multi-level with Multiple Aggregations):\")\n",
    "                print(satellite_pivot_sql_pivoted.head(10))\n",
    "                \n",
    "                # Save SQL results\n",
    "                satellite_pivot_sql_pivoted.to_csv(\n",
    "                    os.path.join(OUTPUT_PATH, \"satellite_pivot_sql.csv\")\n",
    "                )\n",
    "                logging.info(\"SQL pivot table saved to 'satellite_pivot_sql.csv'\")\n",
    "            else:\n",
    "                logging.info(\"SQL query for satellite data returned no results.\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during SQL implementation for satellites: {e}\")\n",
    "        finally:\n",
    "            db_manager.disconnect()\n",
    "\n",
    "# Question 3: Advanced Group-by Operations (Military Base Data)\n",
    "print(\"\\n\\n--- Question 3: Advanced Group-by (Military Base Data) ---\")\n",
    "if not military_bases_df.empty:\n",
    "    site_name_col_mil = \"site_name\"\n",
    "    state_terr_col = \"state_terr\"\n",
    "    component_col = \"component\"\n",
    "    joint_base_col = \"joint_base\"\n",
    "    oper_stat_col = \"oper_stat\"\n",
    "    area_col = \"area\"\n",
    "    perimeter_col = \"perimeter\"\n",
    "    shape_leng_col = \"shape_leng\"\n",
    "    shape_area_col = \"shape_area\"\n",
    "\n",
    "    required_q3_cols = [\n",
    "        site_name_col_mil,\n",
    "        state_terr_col,\n",
    "        component_col,\n",
    "        joint_base_col,\n",
    "        oper_stat_col,\n",
    "        area_col,\n",
    "        perimeter_col,\n",
    "        shape_leng_col,\n",
    "        shape_area_col,\n",
    "    ]\n",
    "    actual_mil_cols = military_bases_df.columns\n",
    "    missing_q3_cols = [col for col in required_q3_cols if col not in actual_mil_cols]\n",
    "\n",
    "    if missing_q3_cols:\n",
    "        logging.error(\n",
    "            f\"Q3: Missing critical military base columns after cleaning: {missing_q3_cols}. Available: {actual_mil_cols}\"\n",
    "        )\n",
    "    else:\n",
    "        logging.info(\"Q3: All required military base columns are present.\")\n",
    "        \n",
    "        # Table 1: Basic base information\n",
    "        base_info_df = military_bases_df[\n",
    "            [\n",
    "                site_name_col_mil,\n",
    "                state_terr_col,\n",
    "                component_col,\n",
    "                joint_base_col,\n",
    "                oper_stat_col,\n",
    "            ]\n",
    "        ].copy()\n",
    "        \n",
    "        # Table 2: Geographical and size metrics\n",
    "        base_geo_df = military_bases_df[\n",
    "            [site_name_col_mil, area_col, perimeter_col, shape_leng_col, shape_area_col]\n",
    "        ].copy()\n",
    "\n",
    "        # Clean numeric columns\n",
    "        for col_to_num in [area_col, perimeter_col, shape_leng_col, shape_area_col]:\n",
    "            if col_to_num in base_geo_df.columns:\n",
    "                # Handle comma as decimal separator\n",
    "                if base_geo_df[col_to_num].dtype == \"object\":\n",
    "                    base_geo_df[col_to_num] = base_geo_df[col_to_num].str.replace(\n",
    "                        \",\", \".\", regex=False\n",
    "                    )\n",
    "                base_geo_df[col_to_num] = pd.to_numeric(\n",
    "                    base_geo_df[col_to_num], errors=\"coerce\"\n",
    "                )\n",
    "\n",
    "        # Merge the two tables\n",
    "        merged_bases_df = pd.merge(\n",
    "            base_info_df, base_geo_df, on=site_name_col_mil, how=\"inner\"\n",
    "        )\n",
    "        \n",
    "        print(\"\\n-- Pandas Implementation (Military Bases) --\")\n",
    "        print(\"Base Info Table (head):\")\n",
    "        print(base_info_df.head())\n",
    "        print(\"\\nBase Geographical Metrics Table (head):\")\n",
    "        print(base_geo_df.head())\n",
    "        print(\"\\nMerged Military Bases Table (head):\")\n",
    "        print(merged_bases_df.head())\n",
    "\n",
    "        # Define strategic importance function\n",
    "        def calculate_strategic_importance(group):\n",
    "            \"\"\"Calculate strategic importance score for a group of bases\"\"\"\n",
    "            # Map operational status to numeric values\n",
    "            oper_stat_mapping = {\"ACTIVE\": 1.0, \"INACTIVE\": 0.5, \"UNKNOWN\": 0.25}\n",
    "            \n",
    "            # Convert operational status to numeric and get mean\n",
    "            oper_stat_numeric = group[oper_stat_col].map(oper_stat_mapping).fillna(0.1)\n",
    "            mean_oper_stat = oper_stat_numeric.mean()\n",
    "            \n",
    "            # Get mean area and perimeter (handle NaN values)\n",
    "            mean_area = group[area_col].mean() if group[area_col].notna().any() else 0\n",
    "            mean_perimeter = group[perimeter_col].mean() if group[perimeter_col].notna().any() else 0\n",
    "            \n",
    "            # Calculate weighted strategic importance score\n",
    "            # Normalize area and perimeter to similar scales for fair weighting\n",
    "            normalized_area = mean_area / 1000 if mean_area > 0 else 0  # Divide by 1000 to normalize\n",
    "            normalized_perimeter = mean_perimeter / 100 if mean_perimeter > 0 else 0  # Divide by 100 to normalize\n",
    "            \n",
    "            score = (\n",
    "                (0.4 * normalized_area) +           # 40% weight on area\n",
    "                (0.3 * normalized_perimeter) +      # 30% weight on perimeter  \n",
    "                (0.3 * mean_oper_stat * 100)        # 30% weight on operational status (scaled up)\n",
    "            )\n",
    "            \n",
    "            return score if pd.notna(score) else 0\n",
    "\n",
    "        try:\n",
    "            # Advanced groupby operations\n",
    "            military_groupby_pandas = merged_bases_df.groupby([state_terr_col, component_col]).agg({\n",
    "                site_name_col_mil: 'count',                    # Count of bases\n",
    "                area_col: 'mean',                              # Average area\n",
    "                shape_leng_col: 'std',                         # Standard deviation of Shape_Leng\n",
    "                # Apply custom function to entire group for strategic importance\n",
    "                oper_stat_col: lambda x: calculate_strategic_importance(\n",
    "                    merged_bases_df[merged_bases_df.index.isin(x.index)]\n",
    "                )\n",
    "            }).round(4)\n",
    "            \n",
    "            # Rename columns for clarity\n",
    "            military_groupby_pandas.columns = [\n",
    "                'base_count',\n",
    "                'average_area', \n",
    "                'std_dev_shape_length',\n",
    "                'strategic_importance_score'\n",
    "            ]\n",
    "            \n",
    "            military_groupby_pandas = military_groupby_pandas.reset_index()\n",
    "            \n",
    "            print(\"\\nPandas Groupby Results (Military Bases):\")\n",
    "            print(military_groupby_pandas.head(10))\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during Pandas groupby for military bases: {e}\")\n",
    "\n",
    "        print(\"\\n-- SQL Implementation (Military Bases) --\")\n",
    "        try:\n",
    "            db_manager.connect()\n",
    "            \n",
    "            # Load data into SQL tables\n",
    "            db_manager.df_to_table(base_info_df, \"base_info\", if_exists=\"replace\")\n",
    "            db_manager.df_to_table(base_geo_df, \"base_geometrics\", if_exists=\"replace\")\n",
    "            logging.info(\"Military base data loaded into SQL tables.\")\n",
    "\n",
    "            # Register custom aggregate function for standard deviation\n",
    "            class StdevAgg:\n",
    "                def __init__(self):\n",
    "                    self.values = []\n",
    "\n",
    "                def step(self, value):\n",
    "                    if value is not None:\n",
    "                        self.values.append(float(value))\n",
    "\n",
    "                def finalize(self):\n",
    "                    if len(self.values) < 2:\n",
    "                        return 0\n",
    "                    return np.std(self.values, ddof=1)\n",
    "\n",
    "            db_manager.conn.create_aggregate(\"stdev\", 1, StdevAgg)\n",
    "            logging.info(\"Registered 'stdev' aggregate function in SQLite.\")\n",
    "\n",
    "            # SQL query with strategic importance calculation\n",
    "            sql_query_military = f\"\"\"\n",
    "            SELECT\n",
    "                bi.\"{state_terr_col}\", \n",
    "                bi.\"{component_col}\",\n",
    "                COUNT(bi.\"{site_name_col_mil}\") AS base_count,\n",
    "                AVG(CAST(bg.\"{area_col}\" AS FLOAT)) AS average_area,\n",
    "                STDEV(CAST(bg.\"{shape_leng_col}\" AS FLOAT)) AS std_dev_shape_length,\n",
    "                -- Strategic importance calculation\n",
    "                (0.4 * AVG(COALESCE(CAST(bg.\"{area_col}\" AS FLOAT), 0)) / 1000.0) + \n",
    "                (0.3 * AVG(COALESCE(CAST(bg.\"{perimeter_col}\" AS FLOAT), 0)) / 100.0) + \n",
    "                (0.3 * AVG(\n",
    "                    CASE UPPER(bi.\"{oper_stat_col}\")\n",
    "                        WHEN 'ACTIVE' THEN 1.0 \n",
    "                        WHEN 'INACTIVE' THEN 0.5 \n",
    "                        WHEN 'UNKNOWN' THEN 0.25 \n",
    "                        ELSE 0.1\n",
    "                    END\n",
    "                ) * 100) AS strategic_importance_score\n",
    "            FROM base_info bi \n",
    "            JOIN base_geometrics bg ON bi.\"{site_name_col_mil}\" = bg.\"{site_name_col_mil}\"\n",
    "            GROUP BY bi.\"{state_terr_col}\", bi.\"{component_col}\"\n",
    "            ORDER BY bi.\"{state_terr_col}\", bi.\"{component_col}\";\n",
    "            \"\"\"\n",
    "            \n",
    "            logging.info(\"Executing SQL query for military groupby...\")\n",
    "            military_groupby_sql_results = db_manager.fetch_query(sql_query_military)\n",
    "\n",
    "            if military_groupby_sql_results:\n",
    "                military_groupby_sql_df = pd.DataFrame(\n",
    "                    military_groupby_sql_results,\n",
    "                    columns=[\n",
    "                        state_terr_col,\n",
    "                        component_col,\n",
    "                        \"base_count\",\n",
    "                        \"average_area\",\n",
    "                        \"std_dev_shape_length\",\n",
    "                        \"strategic_importance_score\",\n",
    "                    ],\n",
    "                )\n",
    "                print(\"\\nSQL Groupby Results (Military Bases):\")\n",
    "                print(military_groupby_sql_df.head(10))\n",
    "            else:\n",
    "                logging.info(\"SQL query for military base data returned no results.\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during SQL implementation for military bases: {e}\")\n",
    "        finally:\n",
    "            db_manager.disconnect()\n",
    "\n",
    "        # State Strategic Profile\n",
    "        print(\"\\n-- State Strategic Profile --\")\n",
    "        if 'military_groupby_pandas' in locals() and not military_groupby_pandas.empty:\n",
    "            state_strategic_profile_pandas = (\n",
    "                military_groupby_pandas.groupby(state_terr_col)\n",
    "                .agg({\n",
    "                    'base_count': 'sum',                        # Total bases per state\n",
    "                    'average_area': 'mean',                     # Average of component averages\n",
    "                    'std_dev_shape_length': 'mean',             # Average geographical spread\n",
    "                    'strategic_importance_score': 'mean'        # Average strategic importance\n",
    "                })\n",
    "                .round(4)\n",
    "                .reset_index()\n",
    "            )\n",
    "            \n",
    "            # Rename columns for clarity\n",
    "            state_strategic_profile_pandas.columns = [\n",
    "                state_terr_col,\n",
    "                'total_bases',\n",
    "                'avg_base_area_state',\n",
    "                'avg_geographical_spread',\n",
    "                'avg_strategic_score_state'\n",
    "            ]\n",
    "            \n",
    "            print(\"\\nState Strategic Profile (from Pandas data):\")\n",
    "            print(state_strategic_profile_pandas.head())\n",
    "            \n",
    "            state_strategic_profile_pandas.to_csv(\n",
    "                os.path.join(OUTPUT_PATH, \"state_strategic_profile_pandas.csv\"),\n",
    "                index=False,\n",
    "            )\n",
    "            logging.info(\n",
    "                \"State strategic profile (Pandas) saved to 'state_strategic_profile_pandas.csv'\"\n",
    "            )\n",
    "\n",
    "        if 'military_groupby_sql_df' in locals() and not military_groupby_sql_df.empty:\n",
    "            state_strategic_profile_sql = (\n",
    "                military_groupby_sql_df.groupby(state_terr_col)\n",
    "                .agg({\n",
    "                    'base_count': 'sum',\n",
    "                    'average_area': 'mean',\n",
    "                    'std_dev_shape_length': 'mean',\n",
    "                    'strategic_importance_score': 'mean'\n",
    "                })\n",
    "                .round(4)\n",
    "                .reset_index()\n",
    "            )\n",
    "            \n",
    "            # Rename columns for clarity\n",
    "            state_strategic_profile_sql.columns = [\n",
    "                state_terr_col,\n",
    "                'total_bases',\n",
    "                'avg_base_area_state', \n",
    "                'avg_geographical_spread',\n",
    "                'avg_strategic_score_state'\n",
    "            ]\n",
    "            \n",
    "            print(\"\\nState Strategic Profile (from SQL data):\")\n",
    "            print(state_strategic_profile_sql.head())\n",
    "            \n",
    "            state_strategic_profile_sql.to_csv(\n",
    "                os.path.join(OUTPUT_PATH, \"state_strategic_profile_sql.csv\"),\n",
    "                index=False,\n",
    "            )\n",
    "            logging.info(\n",
    "                \"State strategic profile (SQL) saved to 'state_strategic_profile_sql.csv'\"\n",
    "            )\n",
    "\n",
    "# Question 4: Multi-Level Data Transformation and Pivoting (Satellite Data)\n",
    "print(\"\\n\\n--- Question 4: Multi-Level Pivoting (Satellite Data) ---\")\n",
    "if not satellite_df.empty and name_col_sat in satellite_df.columns:\n",
    "    logging.info(\"Starting Question 4: Multi-Level Pivoting (Satellite Data)\")\n",
    "    q4_sat_df = satellite_df.copy()\n",
    "\n",
    "    if not all(\n",
    "        col in q4_sat_df.columns for col in [mass_col, launch_date_col, country_col]\n",
    "    ):\n",
    "        logging.error(\n",
    "            f\"Q4: Missing columns for satellite advanced pivoting. Need: {mass_col}, {launch_date_col}, {country_col}. Available: {q4_sat_df.columns}\"\n",
    "        )\n",
    "    else:\n",
    "        # Clean mass column if needed\n",
    "        if q4_sat_df[mass_col].dtype == \"object\":\n",
    "            q4_sat_df[mass_col] = (\n",
    "                q4_sat_df[mass_col].astype(str).str.replace(\",\", \"\", regex=False)\n",
    "            )\n",
    "            q4_sat_df[mass_col] = pd.to_numeric(q4_sat_df[mass_col], errors=\"coerce\")\n",
    "\n",
    "        # Create size categories based on launch mass\n",
    "        def categorize_satellite_size(mass):\n",
    "            if pd.isna(mass):\n",
    "                return None\n",
    "            elif mass < 500:\n",
    "                return \"Small\"\n",
    "            elif mass <= 2000:\n",
    "                return \"Medium\"\n",
    "            else:\n",
    "                return \"Large\"\n",
    "\n",
    "        q4_sat_df[\"size_category\"] = q4_sat_df[mass_col].apply(categorize_satellite_size)\n",
    "        \n",
    "        print(\"\\nSatellites with Size Category (sample):\")\n",
    "        size_sample = q4_sat_df[[name_col_sat, mass_col, \"size_category\"]].dropna(subset=[mass_col])\n",
    "        print(size_sample.head(10))\n",
    "        print(f\"\\nSize category distribution:\")\n",
    "        print(q4_sat_df[\"size_category\"].value_counts())\n",
    "\n",
    "        # Process launch dates and create decades\n",
    "        q4_sat_df[launch_date_col] = pd.to_datetime(q4_sat_df[launch_date_col], errors=\"coerce\")\n",
    "        q4_sat_df[\"launch_year\"] = q4_sat_df[launch_date_col].dt.year\n",
    "\n",
    "        def categorize_decade(year):\n",
    "            if pd.isna(year):\n",
    "                return None\n",
    "            elif 1990 <= year <= 1999:\n",
    "                return \"1990s\"\n",
    "            elif 2000 <= year <= 2009:\n",
    "                return \"2000s\"\n",
    "            elif 2010 <= year <= 2019:\n",
    "                return \"2010s\"\n",
    "            elif 2020 <= year <= 2029:\n",
    "                return \"2020s\"\n",
    "            else:\n",
    "                return \"Other\"\n",
    "\n",
    "        q4_sat_df[\"launch_decade\"] = q4_sat_df[\"launch_year\"].apply(categorize_decade)\n",
    "        \n",
    "        print(\"\\nSatellites with Launch Decade (sample):\")\n",
    "        decade_sample = q4_sat_df[[name_col_sat, launch_date_col, \"launch_year\", \"launch_decade\"]].dropna(subset=[\"launch_year\"])\n",
    "        print(decade_sample.head(10))\n",
    "        print(f\"\\nDecade distribution:\")\n",
    "        print(q4_sat_df[\"launch_decade\"].value_counts())\n",
    "\n",
    "        # Filter out rows with missing key data\n",
    "        q4_filtered_df = q4_sat_df.dropna(subset=[\n",
    "            \"launch_decade\", \"size_category\", country_col, name_col_sat\n",
    "        ])\n",
    "        \n",
    "        if not q4_filtered_df.empty:\n",
    "            try:\n",
    "                # Create multi-level pivot table (counts)\n",
    "                satellite_multilevel_pivot_counts = pd.pivot_table(\n",
    "                    q4_filtered_df,\n",
    "                    index=[country_col, \"size_category\"],  # Multi-level index\n",
    "                    columns=\"launch_decade\",               # Decades as columns\n",
    "                    values=name_col_sat,                   # Count satellites\n",
    "                    aggfunc=\"count\",\n",
    "                    fill_value=0\n",
    "                )\n",
    "                \n",
    "                print(\"\\nMulti-level Pivot Table (Satellite Counts by Country, Size, Decade):\")\n",
    "                print(satellite_multilevel_pivot_counts.head(15))\n",
    "                \n",
    "                satellite_multilevel_pivot_counts.to_csv(\n",
    "                    os.path.join(OUTPUT_PATH, \"satellite_multilevel_pivot_counts.csv\")\n",
    "                )\n",
    "                logging.info(\n",
    "                    \"Satellite multi-level pivot (counts) saved to 'satellite_multilevel_pivot_counts.csv'\"\n",
    "                )\n",
    "\n",
    "                # Calculate percentage growth between decades\n",
    "                decades_present = [col for col in [\"1990s\", \"2000s\", \"2010s\", \"2020s\"] \n",
    "                                 if col in satellite_multilevel_pivot_counts.columns]\n",
    "                \n",
    "                if len(decades_present) > 1:\n",
    "                    satellite_growth_pivot = satellite_multilevel_pivot_counts[decades_present].copy()\n",
    "                    \n",
    "                    # Calculate growth between consecutive decades\n",
    "                    for i in range(1, len(decades_present)):\n",
    "                        current_decade = decades_present[i]\n",
    "                        previous_decade = decades_present[i-1]\n",
    "                        growth_col_name = f\"Growth_{previous_decade}_to_{current_decade}_pct\"\n",
    "                        \n",
    "                        # Calculate percentage growth: ((Current - Previous) / Previous) * 100\n",
    "                        # Handle division by zero\n",
    "                        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                            growth = ((satellite_growth_pivot[current_decade] - \n",
    "                                     satellite_growth_pivot[previous_decade]) / \n",
    "                                    satellite_growth_pivot[previous_decade].replace(0, np.nan)) * 100\n",
    "                        \n",
    "                        satellite_growth_pivot[growth_col_name] = growth.fillna(0)\n",
    "                    \n",
    "                    # Keep only growth columns (remove original count columns)\n",
    "                    growth_columns = [col for col in satellite_growth_pivot.columns \n",
    "                                    if col.startswith(\"Growth_\")]\n",
    "                    satellite_growth_pivot = satellite_growth_pivot[growth_columns]\n",
    "                    \n",
    "                    # Replace infinite values with 0\n",
    "                    satellite_growth_pivot = satellite_growth_pivot.replace([np.inf, -np.inf], 0)\n",
    "                    \n",
    "                    print(\"\\nMulti-level Pivot Table (Satellite Percentage Growth between Decades):\")\n",
    "                    print(satellite_growth_pivot.head(15))\n",
    "                    \n",
    "                    satellite_growth_pivot.to_csv(\n",
    "                        os.path.join(OUTPUT_PATH, \"satellite_percentage_growth_pivot.csv\")\n",
    "                    )\n",
    "                    logging.info(\n",
    "                        \"Satellite percentage growth pivot saved to 'satellite_percentage_growth_pivot.csv'\"\n",
    "                    )\n",
    "                else:\n",
    "                    logging.info(\"Q4: Not enough decade columns to calculate growth.\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error creating multi-level pivot table for satellites (Q4): {e}\")\n",
    "        else:\n",
    "            logging.warning(\"Q4: No valid data remaining after filtering for pivot table.\")\n",
    "else:\n",
    "    logging.warning(\n",
    "        \"Satellite DataFrame is empty or key columns missing, skipping Question 4.\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
